"""
Node Classification for the Bitcoin dataset
"""
from sklearn.preprocessing import MinMaxScaler, StandardScaler
import ArgParser
import NodeClassification as nd
import pandas as pd
import time

rnd_seed = 42


def Bitcoin_EF_analysis_selected_nodes(prod_data_path, graph, features_filename, stats_file,
                                       feat_imp_filename, flag, binary, seed, exp_id,
                                       extra_analysis):
    """
    Bitcoin Feature Engineering
    """
    print("\tRead features for anchor nodes.")
    start_time = time.time()
    all_node_features_df = pd.read_csv(features_filename)
    selected_node_list = all_node_features_df.loc[all_node_features_df['is_anchor'] == 1,
                                                  'node'].tolist()
    features_df = all_node_features_df.loc[all_node_features_df['node'].isin(selected_node_list)]
    print("\t\tTime elapsed {} seconds.".format(time.time() - start_time))

    # make ready for classification
    y = features_df['isp'].tolist()  # only anchor nodes where selected
    X_orig = features_df.drop(['node', 'address', 'isp', 'is_anchor', 'timestamp', 'label', 'txId'],
                              axis=1)
    feature_names = X_orig.columns
    X_orig = X_orig.values.tolist()

    # split the train and test set
    print("\tTrain-Test split.")
    X_train, X_test, y_train, y_test = nd.train_test_split(X_orig, y, seed)

    # classification
    print('\tApplying classification.')
    start_time = time.time()
    rf_perf, rf_clf, lr_perf, lr_clf = nd.rf_lr_classification(X_train, X_test, y_train,
                                                               y_test, stats_file, flag, binary,
                                                               exp_id, print_report=True)
    print("\t\tTime elapsed {} seconds.".format(time.time() - start_time))

    # calculates and saves features importance
    feature_imp_df = nd.RF_sorted_feature_importance(rf_clf, feature_names)
    feature_imp_df.to_csv(feat_imp_filename, index=False)

    if extra_analysis:
        # Feature importance
        print("\tInvestigate feature importance.")
        png_file = prod_data_path + '/' + graph + '_' + flag + '_FE_feature_impo.png'
        nd.RF_feature_imp(X_train, y_train, feature_names, png_file)

        # plot t-SNE graph
        print("\tt-SNE graph.")
        values = X_orig
        groups = y
        png_file = prod_data_path + '/' + graph + '_' + flag + '_FE_tsne.png'
        nd.plot_TSNE(values, groups, png_file)

    print("FE node classification finished.")


def bitcoin_prepare_data_for_concat_fe_emb(emb_file, fe_file):
    """
    pre-process the data for the node classification of a new dataset consisting of the
    engineered features and the embeddings
    """
    # read embedding
    emb_df = pd.read_csv(emb_file, sep=' ', skiprows=1, header=None)
    emb_df.columns = ['node'] + [f'emb_{i}' for i in range(emb_df.shape[1] - 1)]

    # read node list
    node_df = pd.read_csv(fe_file)
    # scale features
    meta_data_col = ['node', 'address', 'isp', 'is_anchor', 'timestamp', 'txId', 'label']
    feature_col = [f for f in node_df.columns if f not in meta_data_col]
    scaler = StandardScaler()
    node_df[feature_col] = scaler.fit_transform(node_df[feature_col])

    # merge
    merged_df = emb_df.merge(node_df, on='node', how='left')

    # datasets for  BINARY classification
    X = merged_df[merged_df['is_anchor'] == 1]  # only anchor nodes
    y = X['isp'].tolist()
    X = X.drop(meta_data_col, axis=1)
    X = X.values.tolist()

    # split the train and test set
    X_train, X_test, y_train, y_test = nd.train_test_split(X, y, rnd_seed)

    return X_train, X_test, y_train, y_test


def bitcoin_nd_clf_fe_emb_combined(emb_file, fe_file, stats_file, flag, binary, exp_id):
    """
    apply the node classification based on a new feature set constructed by combining the
    engineered features and the (structural) embedding generated by an automatic method like node2vec
    """
    print("\tConcatenating embedding with engineered features for node classification.")
    # data preparation
    X_train, X_test, y_train, y_test = bitcoin_prepare_data_for_concat_fe_emb(emb_file, fe_file)

    # classification
    print('\tApplying classification.')
    start_time = time.time()
    nd.rf_lr_classification(X_train, X_test, y_train, y_test, stats_file, flag,
                            binary, exp_id, print_report=True)
    print("\tTime elapsed {} seconds.".format(time.time() - start_time))


def main():
    """
    Experiments
    """
    # path setting
    binary = True  # binary or multi-class classification.ATTENTION: always use BINARY classification

    # retrieve arguments from argument parser
    args = ArgParser.parse_args()
    subgraph_path = args.input
    graph_filename = args.graph
    prod_data_path = args.output

    flag = args.flag
    clf_opt = args.clf_opt
    exp_id = args.exp_id

    stats_file = prod_data_path + 'stats_' + flag + '.csv'

    edges_filename = subgraph_path + 'edges_' + graph_filename + '.csv'
    nodes_filename = subgraph_path + 'nodes_' + graph_filename + '.csv'
    features_filename = prod_data_path + 'features_' + graph_filename + '.csv'

    feat_imp_filename = prod_data_path + 'feature_importance_' + graph_filename + '.csv'

    if clf_opt == 'fe':
        # ------------------ Feature Engineering ------------------
        # read the input file and generating the features and the labels set
        print("Node Classification --- Feature Engineering ---")

        Bitcoin_EF_analysis_selected_nodes(prod_data_path, graph_filename, features_filename,
                                           stats_file, feat_imp_filename, 'FE', binary, rnd_seed,
                                           exp_id, extra_analysis=False)
        print("--- Node Classification Feature Engineering is done ---")
        # ---------------------------------------------------------

    elif clf_opt == 'concat':
        # ------------------ FE & Emb concatenating ------------------
        print("Node classification: Concat. FE &" + flag + " embeddings.")

        emb_file = prod_data_path + 'emb_' + str(flag) + '_' + graph_filename + '.emb'
        fe_file = features_filename
        bitcoin_nd_clf_fe_emb_combined(emb_file, fe_file, stats_file, flag, binary, exp_id)
        # ---------------------------------------------------------

    else:
        # ------------------ RiWalk -------------------------------
        print("Node classification: --- RiWalk - " + flag + "---")

        # set file names
        emb_filename = prod_data_path + 'emb_' + str(flag) + '_' + graph_filename + '.emb'

        nd.RiWalk_analysis_selected_nodes(prod_data_path, graph_filename, emb_filename,
                                          nodes_filename, stats_file,
                                          flag, binary, exp_id, extra_analysis=False)
        print("--- Classification RiWalk is done ---")
        # ---------------------------------------------------------


if __name__ == '__main__':
    main()
